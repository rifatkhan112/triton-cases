import os
import torch
import anthropic
from parallel_sparse_reward_propagation.code.triton_implementation import sparse_reward_propagation_triton
from parallel_sparse_reward_propagation.code.naive_implementation import sparse_reward_propagation_naive

# ‚úÖ Load API Key Securely
API_KEY = os.getenv("CLAUDE_API_KEY")
if not API_KEY:
    raise ValueError("‚ö†Ô∏è CLAUDE_API_KEY is not set. Please set it before running the script.")

client = anthropic.Anthropic(api_key=API_KEY)

# ‚úÖ Define test function
def run_claude_verification():
    print("üöÄ Running Claude Verification")

    # Define the test case parameters
    B, S = 4, 4096  # Batch size & sequence length
    dtype = torch.float32
    device = "cuda"

    # Generate synthetic input tensors
    rewards = torch.randn((B, S), dtype=dtype, device=device, requires_grad=True)
    discount_factor = 0.99

    # Run reference implementation
    ref_output = sparse_reward_propagation_naive(rewards, discount_factor)

    # Run Triton implementation
    tri_output = sparse_reward_propagation_triton(rewards, discount_factor)

    # ‚úÖ Compute key metrics instead of sending full tensors
    mae = torch.mean(torch.abs(ref_output - tri_output)).item()
    mad = torch.max(torch.abs(ref_output - tri_output)).item()
    percent_diff = (torch.abs(ref_output - tri_output) / (torch.abs(ref_output) + 1e-8)).mean().item()

    # ‚úÖ Updated prompt (MUCH smaller)
    prompt = f"""
    You are given a comparison between two implementations of sparse reward propagation.

    - Mean Absolute Error (MAE): {mae}
    - Maximum Absolute Difference (MAD): {mad}
    - Mean Percentage Difference: {percent_diff * 100:.5f}%

    Check if the numerical differences are within an acceptable tolerance (1e-5).
    If they are, respond with "Pass ‚úÖ".
    If not, respond with "Fail ‚ùå" and suggest possible reasons for the discrepancy.
    """

    print("üöÄ Running Claude Verification Attempt 1/10...")

    # ‚úÖ Fix: Use Correct Claude Model Name
    try:
        response = client.messages.create(
            model="claude-3-5-sonnet-20241022",  # ‚úÖ Corrected model name
            max_tokens=8192,  # ‚úÖ Set max tokens to 8192
            messages=[{"role": "user", "content": prompt}]
        )

        result = response.content[0].text
        print(f"üîç Claude Verification Result: {result}")

        # Check if verification passed
        if "Pass ‚úÖ" in result:
            print("‚úÖ Claude Verification PASSED!")
        else:
            print("‚ùå Claude Verification FAILED! Investigate differences.")

    except anthropic.AuthenticationError as e:
        print(f"‚ö†Ô∏è Authentication Error: {e}")
        print("üëâ Please check if your CLAUDE_API_KEY is correct.")
    except anthropic.NotFoundError:
        print("‚ùå Model not found. Ensure you are using the correct model name: 'claude-3-5-sonnet-20241022'.")
    except Exception as e:
        print(f"‚ùå Unexpected Error: {e}")

# ‚úÖ Run the verification script
if __name__ == "__main__":
    run_claude_verification()
